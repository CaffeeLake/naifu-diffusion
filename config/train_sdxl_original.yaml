name: test-run
target: modules.train_sdxl_original.setup

denoiser:
  target: models.sgm.denoiser.DiscreteDenoiser
  sigma_sampler: models.sgm.sigma_sampling.DiscreteSampling
  params:
    scaling: models.sgm.denoiser_scaling.EpsScaling
    discretization: models.sgm.discretizer.LegacyDDPMDiscretization
  weighting: models.sgm.denoiser_weighting.EpsWeighting

trainer:
  model_path: ../stable-diffusion-xl-base-1.0/sd_xl_base_1.0.safetensors
  batch_size: 32
  seed: 65535
  wandb_id: "train_sdxl_original"
  use_xformers: true
  accumulate_grad_batches: 1
  gradient_clip_val: 0.1

  save_format: safetensors
  checkpoint_dir: checkpoint
  checkpoint_freq: 2
  checkpoint_steps: -1
  save_weights_only: true
  max_epochs: 20
  max_steps: -1

advanced:
  vae_encode_batch_size: -1 # same as batch_size
  train_text_encoder_1: true
  train_text_encoder_2: true
  text_encoder_1_lr: 3e-6
  text_encoder_2_lr: 3e-6
  offset_noise: true
  offset_noise_val: 0.1
  timestep_start: 0
  timestep_end: 1000

lightning:
  accelerator: gpu
  devices: -1
  precision: 16-mixed

dataset:
  name: data.bucket.AspectRatioDataset
  target_area: 262_144
  min_size: 512
  max_size: 512
  img_path: ../font2png/exports
  max_token_length: 225 # [75, 150, 225]

optimizer:
  name: bitsandbytes.optim.PagedLion8bit
  params:
    lr: 5e-6
    weight_decay: 0

scheduler:
  name: transformers.get_cosine_with_hard_restarts_schedule_with_warmup
  params:
    num_warmup_steps: 124
    num_training_steps: 2480
    num_cycles: 10
    last_epoch: -1

sampling:
  enabled: false
  use_wandb: true
  seed: 65535
  height: 512
  width: 512
  every_n_steps: -1
  every_n_epochs: 1
  save_dir: "samples"
  prompts:
    - "u000039, 9"
