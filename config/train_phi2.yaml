name: test-run
target: modules.train_phi.setup

trainer:
  model_path: microsoft/phi-2
  batch_size: 16
  seed: 1138
  wandb_id: "phi2"
  accumulate_grad_batches: 1
  gradient_clip_val: 1.0

  save_format: diffusers
  checkpoint_dir: checkpoint
  checkpoint_freq: 1
  checkpoint_steps: 2500
  eval_samples: 100
  eval_steps: 300
  eval_epoch: 1
  max_epochs: 60
  max_steps: -1
  
lightning:
  accelerator: gpu
  devices: -1
  precision: bf16-mixed

dataset:
  name: data.text_dataset.TextDataset
  cutoff_len: 2048
  prompt_style: 
    name: "data.prompt_style.Phi2QAStyle"
    prompt_field: question
    output_field: answer
  train_dataset: 
    path: 'microsoft/orca-math-word-problems-200k'
    split: 'train[:90%]'
  val_dataset: 
    path: 'microsoft/orca-math-word-problems-200k'
    split: 'train[90%:]'
  
optimizer:
  name: bitsandbytes.optim.AdamW8bit
  params:
    lr: 4e-4
    weight_decay: 1e-2

scheduler:
  name: transformers.get_constant_schedule_with_warmup
  params:
    num_warmup_steps: 0
    last_epoch: -1

sampling:
  enabled: false
  max_length: 50
  every_n_steps: 500
  every_n_epochs: 1
  prompts:
    - "1girl, long hair, white hair"
    - "1girl, purple hair"
    - "gothic lolita"
    - "hatsune miku"